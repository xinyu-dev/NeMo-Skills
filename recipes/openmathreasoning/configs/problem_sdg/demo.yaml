cluster: local
base_output_dir: /workspace/openmathreasoning-demo
expname: omr-demo
suffix: nim  # Suffix for experiment names


# this is really .jsonl, but we gitignore it, so changing extension
input_file: /nemo_run/code/recipes/openmathreasoning/configs/problem_sdg/example-data.txt

# Define model server parameters
generate_kwargs:
  # Model to be used for data processing stages
  model: gpt-4o-mini
  # Server type to launch the model
  server_type: openai
  # OpenAI API endpoint
  server_address: https://api.openai.com/v1

# List of datasets to run problem decontamination with
decontamination_datasets:
  # - math
  - aime24
  - aime25
  # - amc23
  # - college_math
  # - gaokao2023en
  # - gsm8k
  # - minerva_math
  # - olympiadbench
  # - omni-math

pipeline_stages:
  - extract_problems
  - classify_problems
  - extract_answers
  - convert_proofs
  - merge_data
  - decontaminate

directories:
  step-1-extract-problems: ${base_output_dir}/problem-sdg/step-1-extract-problems
  step-2-classify-problems: ${base_output_dir}/problem-sdg/step-2-classify-problems
  step-3-extract-answers: ${base_output_dir}/problem-sdg/step-3-extract-answers
  step-4-convert-proofs: ${base_output_dir}/problem-sdg/step-4-convert-proofs
  step-5-merge-data: ${base_output_dir}/problem-sdg/step-5-merge-data
  step-6-decontaminate: ${base_output_dir}/problem-sdg/step-6-decontamination

# Stage-specific configurations
stages:
  extract_problems:
    output_dir: ${directories.step-1-extract-problems}
    input_file: ${input_file}
    dependencies: null
    stage_kwargs: ${generate_kwargs}

  classify_problems:
    output_dir: ${directories.step-2-classify-problems}
    input_file: ${directories.step-1-extract-problems}/extracted-problems.jsonl
    modes: ['proof', 'mcq', 'binary', 'invalid']
    dependencies:
      - extract_problems # this must be run before this stage
    stage_kwargs: ${generate_kwargs}

  extract_answers:
    output_dir: ${directories.step-3-extract-answers}
    input_file: ${directories.step-2-classify-problems}/invalid/no.jsonl
    dependencies:
      - classify_problems
    stage_kwargs: ${generate_kwargs}

  convert_proofs:
    output_dir: ${directories.step-4-convert-proofs}
    input_file: ${directories.step-2-classify-problems}/proof/yes.jsonl
    dependencies:
      - classify_problems
    stage_kwargs: ${generate_kwargs}

  merge_data:
    output_dir: ${directories.step-5-merge-data}
    proofs_file: ${directories.step-4-convert-proofs}/converted-proofs.jsonl
    answers_file: ${directories.step-3-extract-answers}/extracted-answers.jsonl
    dependencies:
      - extract_answers
      - convert_proofs

  decontaminate:
    output_dir: ${directories.step-6-decontaminate}
    input_file: ${directories.step-5-merge-data}/all-problems.jsonl
    output_file: ${directories.step-6-decontaminate}/contamination-labeled.jsonl
    datasets: ${decontamination_datasets}
    dependencies:
      - merge_data
    # This script runs embedding model locally,
    # so if there're GPUs available, you can use them
    retrieve_similar_kwargs:
      num_gpus: 1
    stage_kwargs: ${generate_kwargs}
